% This file was created with JabRef 2.7.2.
% Encoding: UTF-8

@ARTICLE{Beirlant1997,
  author = {J Beirlant and E J Dudewicz and L Gyorfi and E C van der Meulen},
  title = {Nonparameteric Entropy Estimation: An Overview},
  journal = {International Journal of Mathematics and Statistical Science},
  year = {1997},
  volume = {6.1},
  pages = {17-39},
  owner = {cheese63},
  timestamp = {2011.12.06}
}

@ARTICLE{Bengio2009,
  author = {Yoshua Bengio},
  title = {Learning Deep Architectures for AI},
  journal = {Foundations and Trends in Machine Learning},
  year = {2009},
  volume = {2.1},
  pages = {1-127},
  owner = {cheese63},
  timestamp = {2011.12.06}
}

@BOOK{Bishop2006,
  title = {Pattern Recognition and Machine Learning},
  publisher = {Springer},
  year = {2006},
  author = {Christopher M. Bishop},
  owner = {cheese63},
  timestamp = {2011.12.06}
}

@ARTICLE{Cisek2010,
  author = {Paul Cisek and John F Kalaska},
  title = {Neural mechanisms for interacting with a world full of action choices.},
  journal = {Annu Rev Neurosci},
  year = {2010},
  volume = {33},
  pages = {269--298},
  abstract = {The neural bases of behavior are often discussed in terms of perceptual,
	cognitive, and motor stages, defined within an information processing
	framework that was originally inspired by models of human abstract
	problem solving. Here, we review a growing body of neurophysiological
	data that is difficult to reconcile with this influential theoretical
	perspective. As an alternative foundation for interpreting neural
	data, we consider frameworks borrowed from ethology, which emphasize
	the kinds of real-time interactive behaviors that animals have engaged
	in for millions of years. In particular, we discuss an ethologically-inspired
	view of interactive behavior as simultaneous processes that specify
	potential motor actions and select between them. We review how recent
	neurophysiological data from diverse cortical and subcortical regions
	appear more compatible with this parallel view than with the classical
	view of serial information processing stages.},
  doi = {10.1146/annurev.neuro.051508.135409},
  file = {:/papers/Motor System/2010-Cisek-ActionChoices.pdf:PDF},
  institution = {Groupe de Recherche sur le Système Nerveux Central (FRSQ), Département
	de Physiologie, Université de Montréal, Montréal, Québec H3C3J7,
	Canada. paul.cisek@umontreal.ca},
  keywords = {Animals; Behavior, physiology; Cognition, physiology; Decision Making,
	physiology; Humans; Movement, physiology; Neural Pathways, physiology;
	Neurons, physiology; Psychomotor Performance, physiology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {cheese63},
  pmid = {20345247},
  review = {- Paper about representations of potential actions in computational
	model:
	
	Cisek P. 2006. Integrated neural processes for defining potential
	actions and deciding between them: a computational
	
	model. J. Neurosci. 26(38):9761–70
	
	
	Sahin E, C¸ akmak M, Dogar MR, Ugur E, Ucoluk G. 2007. To afford or
	not to afford: a new formalization of
	
	affordances toward affordance-based robot control. Adaptive Behav.
	15(4):447–71
	
	
	Question: This review and Gold and Shadlen seem to indicate that higher
	level cortical activity can modify primary sensory cortex activity.
	If so, which layer(s) of primary sensory cortex does intention to
	perform an action or make a decision affect the most?},
  timestamp = {2011.07.17},
  url = {http://dx.doi.org/10.1146/annurev.neuro.051508.135409}
}

@ARTICLE{Csicsvari2003,
  author = {Jozsef Csicsvari and Darrell A Henze and Brian Jamieson and Kenneth
	D Harris and Anton Sirota and Péter Barthó and Kensall D Wise and
	György Buzsáki},
  title = {Massively parallel recording of unit and local field potentials with
	silicon-based electrodes.},
  journal = {J Neurophysiol},
  year = {2003},
  volume = {90},
  pages = {1314--1323},
  number = {2},
  month = {Aug},
  __markedentry = {[cheese63]},
  abstract = {Parallel recording of neuronal activity in the behaving animal is
	a prerequisite for our understanding of neuronal representation and
	storage of information. Here we describe the development of micro-machined
	silicon microelectrode arrays for unit and local field recordings.
	The two-dimensional probes with 96 or 64 recording sites provided
	high-density recording of unit and field activity with minimal tissue
	displacement or damage. The on-chip active circuit eliminated movement
	and other artifacts and greatly reduced the weight of the headgear.
	The precise geometry of the recording tips allowed for the estimation
	of the spatial location of the recorded neurons and for high-resolution
	estimation of extracellular current source density. Action potentials
	could be simultaneously recorded from the soma and dendrites of the
	same neurons. Silicon technology is a promising approach for high-density,
	high-resolution sampling of neuronal activity in both basic research
	and prosthetic devices.},
  doi = {10.1152/jn.00116.2003},
  institution = {Center for Molecular and Behavioral Neuroscience, Rutgers, The State
	University of New Jersey, Newark, New Jersey 07102, USA.},
  keywords = {Animals; Brain, physiology; Electrophysiology, methods; Microelectrodes;
	Rats; Rats, Sprague-Dawley; Silicon},
  language = {eng},
  medline-pst = {ppublish},
  owner = {cheese63},
  pii = {90/2/1314},
  pmid = {12904510},
  timestamp = {2011.08.21},
  url = {http://dx.doi.org/10.1152/jn.00116.2003}
}

@ARTICLE{DumitruErhan2010,
  author = {Dumitru Erhan, Yoshua Bengio, Aaron Courville, Pierre-Antoine Manzagol,
	Pascal Vincent, Samy Bengio},
  title = {Why Does Unsupervised Pre-training Help Deep Learning?},
  journal = {Journal of Machine Learning Research},
  year = {2010},
  volume = {11},
  pages = {625-660},
  abstract = {Much recent research has been devoted to learning algorithms for deep
	architectures such as Deep
	
	Belief Networks and stacks of auto-encoder variants, with impressive
	results obtained in several
	
	areas, mostly on vision and language data sets. The best results obtained
	on supervised learning
	
	tasks involve an unsupervised learning component, usually in an unsupervised
	pre-training phase.
	
	Even though these new algorithms have enabled training deep models,
	many questions remain as to
	
	the nature of this difficult learning problem. The main question investigated
	here is the following:
	
	how does unsupervised pre-training work? Answering this questions
	is important if learning in
	
	deep architectures is to be further improved. We propose several explanatory
	hypotheses and test
	
	them through extensive simulations. We empirically show the influence
	of pre-training with respect
	
	to architecture depth, model capacity, and number of training examples.
	The experiments confirm
	
	and clarify the advantage of unsupervised pre-training. The results
	suggest that unsupervised pretraining
	
	guides the learning towards basins of attraction of minima that support
	better generalization
	
	from the training data set; the evidence from these results supports
	a regularization explanation for
	
	the effect of pre-training.},
  file = {:papers/Machine Learning/2010-Erhan-UnsupervisedPreTraining.pdf:PDF},
  owner = {cheese63},
  review = {Papers referred to:
	
	
	Hugo Larochelle, Yoshua Bengio, Jerome Louradour, and Pascal Lamblin.
	Exploring strategies for training deep neural networks. The Journal
	of Machine Learning Research, 10:1–40, January 2009
	
	
	Andrew Y. Ng and Michael I. Jordan. On discriminative vs. generative
	classifiers: A comparison of logistic regression and naive bayes.
	In T.G. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances
	in Neural Information Processing Systems 14 (NIPS’01), pages 841–848,
	2002.
	
	
	Paper on extending conditional distributions in deep nets to exponential
	families:
	
	
	Max Welling, Michal Rosen-Zvi, and Geoffrey E. Hinton. Exponential
	family harmoniums with an application to information retrieval. In
	L.K. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information
	Processing Systems 17 (NIPS’04), pages 1481–1488, Cambridge, MA,
	2005. MIT Press.},
  timestamp = {2011.07.16}
}

@ARTICLE{Ferezou2006,
  author = {Isabelle Ferezou and Sonia Bolea and Carl C H Petersen},
  title = {Visualizing the cortical representation of whisker touch: voltage-sensitive
	dye imaging in freely moving mice.},
  journal = {Neuron},
  year = {2006},
  volume = {50},
  pages = {617--629},
  number = {4},
  month = {May},
  abstract = {Voltage-sensitive dye imaging resolves the spatiotemporal dynamics
	of supragranular subthreshold cortical activity with millisecond
	temporal resolution and subcolumnar spatial resolution. We used a
	flexible fiber optic image bundle to visualize voltage-sensitive
	dye dynamics in the barrel cortex of freely moving mice while simultaneously
	filming whisker-related behavior to generate two movies matched frame-by-frame
	with a temporal resolution of up to 2 ms. Sensory responses evoked
	by passive whisker stimulation lasted longer and spread further across
	the barrel cortex in awake mice compared to anesthetized mice. Passively
	evoked sensory responses were large during behaviorally quiet periods
	and small during active whisking. However, as an exploring mouse
	approached an object while whisking, large-amplitude, propagating
	cortical sensory activity was evoked by active whisker-touch. These
	experiments demonstrate that fiber optics can be used to image cortical
	sensory activity with high resolution in freely moving animals. The
	results demonstrate differential processing of sensory input depending
	upon behavior.},
  doi = {10.1016/j.neuron.2006.03.043},
  file = {:/papers/Tech/2006-Ferezou-FreeMovingVSD.pdf:PDF},
  institution = {Laboratory of Sensory Processing, Brain Mind Institute, SV-BMI-LSENS
	AAB 105, Station 15, Ecole Polytechnique Federale de Lausanne, CH-1015
	Lausanne, Switzerland.},
  keywords = {Anesthesia, General; Animals; Behavior, Animal; Brain Mapping; Diagnostic
	Imaging; Evoked Potentials, Somatosensory, physiology; Fiber Optic
	Technology, methods; Fluorescent Dyes; Image Processing, Computer-Assisted;
	Mice; Optical Fibers; Patch-Clamp Techniques; Somatosensory Cortex,
	physiology; Vibrissae, innervation; Wakefulness, physiology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {cheese63},
  pii = {S0896-6273(06)00270-4},
  pmid = {16701211},
  timestamp = {2011.08.21},
  url = {http://dx.doi.org/10.1016/j.neuron.2006.03.043}
}

@ARTICLE{Fries2009a,
  author = {Pascal Fries},
  title = {Neuronal gamma-band synchronization as a fundamental process in cortical
	computation.},
  journal = {Annu Rev Neurosci},
  year = {2009},
  volume = {32},
  pages = {209--224},
  abstract = {Neuronal gamma-band synchronization is found in many cortical areas,
	is induced by different stimuli or tasks, and is related to several
	cognitive capacities. Thus, it appears as if many different gamma-band
	synchronization phenomena subserve many different functions. I argue
	that gamma-band synchronization is a fundamental process that subserves
	an elemental operation of cortical computation. Cortical computation
	unfolds in the interplay between neuronal dynamics and structural
	neuronal connectivity. A core motif of neuronal connectivity is convergence,
	which brings about both selectivity and invariance of neuronal responses.
	However, those core functions can be achieved simultaneously only
	if converging neuronal inputs are functionally segmented and if only
	one segment is selected at a time. This segmentation and selection
	can be elegantly achieved if structural connectivity interacts with
	neuronal synchronization. I propose that this process is at least
	one of the fundamental functions of gamma-band synchronization, which
	then subserves numerous higher cognitive functions.},
  doi = {10.1146/annurev.neuro.051508.135603},
  file = {:/papers/Oscillations/2009-Fries-GammaSynchronization.pdf:PDF},
  institution = {Donders Institute for Brain, Cognition and Behaviour, Radboud University
	Nijmegen, Nijmegen, The Netherlands. pascal.fries@donders.ru.nl},
  keywords = {Action Potentials, physiology; Animals; Cerebral Cortex, cytology/physiology;
	Cognition, physiology; Cortical Synchronization; Evoked Potentials,
	physiology; Humans; Mental Processes, physiology; Nerve Net, cytology/physiology;
	Neural Pathways, cytology/physiology; Neurons, physiology; Periodicity},
  language = {eng},
  medline-pst = {ppublish},
  owner = {cheese63},
  pmid = {19400723},
  review = {- Potentially interesting paper:
	
	Morita K, Kalra R, Aihara K, Robinson HP. 2008. Recurrent synaptic
	input and the timing of
	
	gamma-frequency-modulated firing of pyramidal cells during neocortical
	“UP” states. J. Neurosci.
	
	28(8):1871–81
	
	
	- Support for coherence hypothesis:
	
	Womelsdorf T, Schoffelen JM, Oostenveld R, Singer W, Desimone R, et
	al. 2007. Modulation of neuronal
	
	interactions through neuronal synchronization. Science 316(5831):1609–12
	
	
	- Talks about a synchrony-based form of winner take all. Two networks
	A and B oscillate with
	
	different frequencies and feed onto network C. Network C will only
	be receptive to the network
	
	that oscillates at the same frequency.
	
	
	- Potentially good computational paper:
	
	Borgers C, Kopell NJ. 2008. Gamma oscillations and stimulus selection.
	Neural Comput. 20(2):383–414
	
	
	- Potentially good papers on cortical connectivity:
	
	Salin PA, Girard P, Kennedy H, Bullier J. 1992. Visuotopic organization
	of corticocortical connections in the
	
	visual system of the cat. J. Comp Neurol. 320(4):415–34
	
	
	Lund JS, Angelucci A, Bressloff PC. 2003. Anatomical substrates for
	functional columns in macaque monkey
	
	primary visual cortex. Cereb. Cortex 13(1):15–24
	
	
	- Papers on modulation of visual areas by behavioral relevance:
	
	Reynolds JH, Chelazzi L. 2004. Attentional modulation of visual processing.
	Annu. Rev. Neurosci. 27:611–47
	
	Reynolds JH, Chelazzi L, Desimone R. 1999. Competitive mechanisms
	subserve attention in macaque areas
	
	V2 and V4. J. Neurosci. 19(5):1736–53},
  timestamp = {2011.07.30},
  url = {http://dx.doi.org/10.1146/annurev.neuro.051508.135603}
}

@ARTICLE{Gold2007,
  author = {Joshua I Gold and Michael N Shadlen},
  title = {The neural basis of decision making.},
  journal = {Annu Rev Neurosci},
  year = {2007},
  volume = {30},
  pages = {535--574},
  abstract = {The study of decision making spans such varied fields as neuroscience,
	psychology, economics, statistics, political science, and computer
	science. Despite this diversity of applications, most decisions share
	common elements including deliberation and commitment. Here we evaluate
	recent progress in understanding how these basic elements of decision
	formation are implemented in the brain. We focus on simple decisions
	that can be studied in the laboratory but emphasize general principles
	likely to extend to other settings.},
  doi = {10.1146/annurev.neuro.29.051605.113038},
  file = {:/papers/Motor System/2007-Gold-DecisionMaking.pdf:PDF},
  institution = {Department of Neuroscience, University of Pennsylvania, Philadelphia,
	Pennsylvania 19104-6074, USA. jigold@mail.med.upenn.edu},
  keywords = {Animals; Brain, anatomy /&/ histology/physiology; Cognition, physiology;
	Decision Making, physiology; Humans; Models, Neurological; Movement,
	physiology; Perception, physiology; Psychomotor Performance, physiology;
	Psychophysics; Volition, physiology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {cheese63},
  pmid = {17600525},
  review = {- Signal detection theory is a mathematical framework for making decisions
	
	 - Hypothesis about world states are encoded as h1, h2
	
	 - Actions associated with world states are encoded as (H1, h1), (H2,
	h2)
	
	 - Values encode the value of taking an action given a world state,
	v(H1 | h1), v(H1 | H2)
	
	 - Sensory input is transformed into evidence about a world state:
	e
	
	 - Likelihoods are computed on the evidence: P(e | h1), P(e | h2)
	
	 - Likelihood ratios can serve as decision variables DV = log( P(e
	| h1) / P(e | h2) )
	
	 - The DV can also include values in the calculation.
	
	 - When the DV reaches a threshold, a decision is made
	
	
	- Sequential analysis deals with a stream of evidence that evolves
	over time: e1, e2, e3, ...
	
	 - The decision variable is computed online and when a certain point
	is reached a decision/action is made
	
	 - The Sequential Probability Ratio Test computes an update weight
	at each step equal to the
	
	 log likelihood of the evidence that arrives at time t: w_t = log(
	P(e_t | h1) / P(e_t | h2) ) )
	
	 - The cumulative sum of w_t's is taken into account as the decision
	variable
	
	
	- Papers that talk about decision variables being encoded in higher
	level cortex:
	
	Brody CD, Hernandez A, Zainos A, Romo R. 2003.Timing and neural encoding
	of somatosensory
	
	parametric working memory in macaque prefrontal cortex. Cereb. Cortex
	13:1196–207
	
	Romo R, Hernandez A, Zainos A. 2004. Neuronal correlates of a perceptual
	decision in ventral
	
	premotor cortex. Neuron 41:165–73
	
	Romo R, Hernandez A, Zainos A, Lemus L, Brody CD. 2002. Neuronal correlates
	of decisionmaking
	
	in secondary somatosensory cortex. Nat. Neurosci. 5:1217–25
	
	
	- Monkeys were given a task where their hand was stimulated with two
	frequencies f1 and f2, and
	
	had to make a decision as to whether f2 > f1
	
	- Area S1 encoded the evidence (the actual frequencies of stimulation),
	and higher order cortex
	
	encoded things that were closer to decision variables. The areas included
	S2, the dorso-lateral
	
	pre-frontal cortex (dlPFC), and especially the medial and ventral
	pre-motor corticies (MPC and VPC)
	
	
	- "One challenge is to understand the apparent redundancy. For example,
	memory traces of f 1 and
	
	f 1/f 2 comparisons are both found in S2, VPC, MPC, and dlPFC. Do
	the subtle differences in how those
	
	computations manifest in the different brain areas indicate subtly
	different roles in these processes?
	
	Or is there simply a continuous flow of information through these
	circuits, such that each performs
	
	a unique role but has continuous access to the computations performed
	by the other circuits?
	
	
	- In a random dot motion (RDM) task, a monkey has to decide if a group
	of random dots is going in
	
	one direction or another.
	
	- Evidence for this task has been traced to be accumulated in the
	middle temporal area (MT/V5).
	
	- "individual MT neurons weakly but significantly predict the monkey’s
	direction decisions, including errors"
	
	- Saccades were invoked by microstimulation of the FEF during the
	decision-making process, and those
	
	saccades tended to deviate towards the direction of the final decision,
	indicating that information about
	
	the decision was shared with motor areas while evidence accumulated.
	
	- Neurons in LIP seem to encode the decision variable for the RDM
	task where reaction time is
	
	important. More specifically they seem to integrate evidence over
	time in the RDM task.
	
	
	- Potentially interesting paper about computing decisions:
	
	Wang XJ. 2002. Probabilistic decision making by slow reverberation
	in cortical circuits. Neuron
	
	36:955–68},
  timestamp = {2011.07.17},
  url = {http://dx.doi.org/10.1146/annurev.neuro.29.051605.113038}
}

@ARTICLE{Hornik1989,
  author = {Kurt Hornik and Maxwell Sinchcombe and Halbert White},
  title = {Multilayer Feedforward Networks are Universal Approximators},
  journal = {Neural Networks},
  year = {1989},
  volume = {2},
  pages = {359-366},
  file = {:/papers/Machine Learning/1981-Hornik-NNUniversalApproximators.pdf:PDF},
  owner = {cheese63},
  timestamp = {2011.12.06}
}

@TECHREPORT{Jaeger2001,
  author = {Herbert Jaeger},
  title = {The echo state approach to analysing and training recurrent neural
	networks},
  institution = {Fraunhofer Institute for Autonomous Intelligent Systems},
  year = {2001},
  abstract = {The report introduces a constructive learning algorithm for
	
	recurrent neural networks, which modifies only the weights to output
	units
	
	in order to achieve the learning task.},
  file = {:/papers/Reservoir Computing/2001-Jaeger-EchoStateRNN.pdf:PDF},
  owner = {cheese63},
  timestamp = {2011.12.01}
}

@ARTICLE{Larouchelle2011,
  author = {Hugo Larouchelle and Iain Murray},
  title = {The Neural Autoregressive Distribution Estimator},
  journal = {Journal of Machine Learning Research},
  year = {2011},
  volume = {15},
  abstract = {We describe a new approach for modeling the
	
	distribution of high-dimensional vectors of discrete
	
	variables. This model is inspired by the
	
	restricted Boltzmann machine (RBM), which
	
	has been shown to be a powerful model of
	
	such distributions. However, an RBM typically
	
	does not provide a tractable distribution
	
	estimator, since evaluating the probability it
	
	assigns to some given observation requires the
	
	computation of the so-called partition function,
	
	which itself is intractable for RBMs of
	
	even moderate size. Our model circumvents
	
	this difficulty by decomposing the joint distribution
	
	of observations into tractable conditional
	
	distributions and modeling each conditional
	
	using a non-linear function similar to a
	
	conditional of an RBM. Our model can also
	
	be interpreted as an autoencoder wired such
	
	that its output can be used to assign valid
	
	probabilities to observations. We show that
	
	this new model outperforms other multivariate
	
	binary distribution estimators on several
	
	datasets and performs similarly to a large (but
	
	intractable) RBM.},
  file = {:papers/Machine Learning/2011-Larouchelle-NADE.pdf:PDF},
  owner = {cheese63},
  timestamp = {2011.07.16}
}

@ARTICLE{Lazar2007,
  author = {Andreea Lazar and Gordon Pipa and Jochen Triesch},
  title = {Fading memory and time series prediction in recurrent networks with
	different forms of plasticity},
  journal = {Neural Networks},
  year = {2007},
  volume = {20},
  pages = {312-322},
  file = {:/papers/Reservoir Computing/2007-NeuralNetworks-SpecialIssue/2007-Lazar-Plasticity.pdf:PDF},
  owner = {cheese63},
  timestamp = {2011.12.06}
}

@ARTICLE{Legenstein2007,
  author = {Robert Legenstein and Wolfgang Maass},
  title = {Edge of chaos and prediction of computational performance for neural
	circuit models},
  journal = {Neural Networks},
  year = {2007},
  volume = {20},
  pages = {323-334},
  file = {:/papers/Reservoir Computing/2007-NeuralNetworks-SpecialIssue/2007-Legenstein-EdgeOfChaos.pdf:PDF},
  owner = {cheese63},
  timestamp = {2011.12.04}
}

@ARTICLE{Maass2002,
  author = {Wolfgang Maass and Thomas Natschlager and Henry Markram},
  title = {Real-Time Computing Without Stable States: A New Framework for Neural
	Computation Based on Perturbations},
  journal = {Neural Computation},
  year = {2002},
  volume = {14},
  pages = {2531-2560},
  abstract = {A key challenge for neural modeling is to explain how a continuous
	
	stream of multimodal input from a rapidly changing environment can
	be
	
	processed by stereotypical recurrent circuits of integrate-and-fire
	neurons
	
	in real time. We propose a new computational model for real-time computing
	
	on time-varying input that provides an alternative to paradigms
	
	based onTuring machines or attractor neural networks. It does not
	require
	
	a task-dependent construction of neural circuits. Instead, it is based
	on
	
	principles of high-dimensional dynamical systems in combination with
	
	statistical learning theory and can be implemented on generic evolved
	or
	
	found recurrent circuitry. It is shown that the inherent transient
	dynamics
	
	of the high-dimensional dynamical system formed by a sufficiently
	large
	
	and heterogeneous neural circuit may serve as universal analog fading
	
	memory. Readout neurons can learn to extract in real time from the
	current
	
	state of such recurrent neural circuit information about current and
	
	past inputs that may be needed for diverse tasks. Stable internal
	states
	
	are not required for giving a stable output, since transient internal
	states
	
	can be transformed by readout neurons into stable target outputs due
	to
	
	the high dimensionality of the dynamical system. Our approach is based
	
	on a rigorous computational model, the liquid state machine, that,
	unlike
	
	Turing machines, does not require sequential transitions between welldefined
	
	discrete internal states. It is supported, as the Turing machine
	
	is, by rigorous mathematical results that predict universal computational
	
	power under idealized conditions, but for the biologically more realistic
	
	scenario of real-time processing of time-varying inputs. Our approach
	
	provides new perspectives for the interpretation of neural coding,
	the
	
	design of experiments and data analysis in neurophysiology, and the
	solution
	
	of problems in robotics and neurotechnology.},
  file = {:/papers/Reservoir Computing/2002-Maas-RealTImePerturbations.pdf:PDF},
  owner = {cheese63},
  timestamp = {2011.12.01}
}

@ARTICLE{Petersen2007a,
  author = {Carl C H Petersen},
  title = {The functional organization of the barrel cortex.},
  journal = {Neuron},
  year = {2007},
  volume = {56},
  pages = {339--355},
  number = {2},
  month = {Oct},
  __markedentry = {[mschachter]},
  abstract = {The tactile somatosensory pathway from whisker to cortex in rodents
	provides a well-defined system for exploring the link between molecular
	mechanisms, synaptic circuits, and behavior. The primary somatosensory
	cortex has an exquisite somatotopic map where each individual whisker
	is represented in a discrete anatomical unit, the "barrel," allowing
	precise delineation of functional organization, development, and
	plasticity. Sensory information is actively acquired in awake behaving
	rodents and processed differently within the barrel map depending
	upon whisker-related behavior. The prominence of state-dependent
	cortical sensory processing is likely to be crucial in our understanding
	of active sensory perception, experience-dependent plasticity and
	learning.},
  doi = {10.1016/j.neuron.2007.09.017},
  file = {:/papers/Somatosensory/2007-Petersen-BarrelCortex.pdf:PDF},
  institution = {Laboratory of Sensory Processing, Brain Mind Institute, SV-BMI-LSENS,
	Station 15, Ecole Polytechnique Federale de Lausanne (EPFL), CH-1015
	Lausanne, Switzerland.},
  keywords = {Animals; Brain Mapping; Models, Neurological; Neuronal Plasticity,
	physiology; Somatosensory Cortex, anatomy /&/ histology/physiology;
	Synapses, physiology; Synaptic Transmission, physiology; Vibrissae,
	innervation},
  language = {eng},
  medline-pst = {ppublish},
  owner = {mschachter},
  pii = {S0896-6273(07)00715-5},
  pmid = {17964250},
  review = {- Deflection of whisker thought to activate mechanoreceptors in hair
	follicle
	
	- Depolarization of primary sensory cell in follicle activates firing
	in neurons of the infraorbital trigeminal sensory nerve
	
	- Trigeminal-thalamo neurons are arranged in "barrellettes" specific
	to one whisker
	
	
	- Trigeminal-thalamo neurons project to Ventral Posterior Medial (VPM)
	portion of thalamus
	
	- VPM neurons respond rapidly and precisely to whisker deflections,
	and have a "best whisker" that they respond to
	
	
	- Trigeminal neurons also project to trigeminal spinal neurons in
	brainstem, the trigeminal spinal interpolaris nucleus
	
	- The trigeminal spinal interpolaris is split into two functionally
	distinct regions.
	
	 - The caudal part is the "extralemniscal pathway", it projects to
	the "septal" regions of mouse S1 and secondary somatosensory cortex
	
	 - The rostral part is the "paralemniscal pathway", it projects to
	the posterior medial (POM) region of the thalamus, which projects
	to layers 1 and 5a of S1, the secondary sensory cortex, and the motor
	cortex
	
	 - "The paralemniscal pathway may therefore play important roles during
	active exploration, perhaps contributing to sensorimotor coordination."
	
	
	- VPM neurons project to layer 4 of the primary sensory cortex and
	form a "barrel map"
	
	- Cortex responds with alot of trial-to-trial variability, and single
	barrels respond to multiple whiskers, in contrast to VPM
	
	
	- Different whiskers have different resonant frequencies, so in addition
	to a spatial map, the barrel cortex might provide a "texture map",
	where the texture of an object interacts with the resonant frequency
	tunings of whiskers. Longer whiskers have lower resonant frequencies.
	
	
	- In rat, layer 4 neurons within a barrel can be subdivided into ones
	that have a specific direction preference, but don't have an obvious
	organization
	
	- Layer 2/3 neurons have maps of direction preferences. The direction
	preferences might be shared across barrels, so that deflection of
	one whisker towards another whisker has an anatomical correlate within
	layer 2/3 between the two barrels
	
	
	- Interesting work using VSD to map spread of depolarization from
	layer 4 to layer 2/3:
	
	1) Petersen, C.C.H., and Sakmann, B. (2001). Functionally independent
	columns of rat somatosensory barrel cortex revealed with voltage
	sensitive dye imaging. J. Neurosci. 21, 8435–8446.
	
	2) Laaris, N., and Keller, A. (2002). Functional independence of layer
	IV barrels. J. Neurophysiol. 87, 1028–1034.
	
	
	- Axons of layer 2/3 neurons form prominent input to layer 5 neurons.
	Layer 5 neurons also receive input from thalamus and layer 4!
	
	
	- POM projects to layer 1 and 5A, and layer 5A projects to layer 2
	
	
	- Whisker trimming reduces connection strength between layer 4 and
	layer 2/3, by reduction of presynaptic transmitter release probability
	
	
	- Map plasticity: when only a single whisker is left, the cortical
	region responding to stimulation of that whisker grows larger. The
	process is reversible. However, the reverse phenomenon happens when
	the animal is allowed to explore a novel environment every 3-4 days.
	The author states that this clearly demonstrates the importance of
	behavioral context for S1 activity.
	
	
	- In layer 2/3, during quiet wakefullness there are large amplitude
	slow oscillations in membrane potental that propagate as waves, visible
	by VSD. During active whisking, the oscillation disappears, the variance
	of the membrane potential decreases, neurons depolarize by a few
	mV.},
  timestamp = {2011.08.16},
  url = {http://dx.doi.org/10.1016/j.neuron.2007.09.017}
}

@ARTICLE{Rizzolatti2001,
  author = {G. Rizzolatti and G. Luppino},
  title = {The cortical motor system.},
  journal = {Neuron},
  year = {2001},
  volume = {31},
  pages = {889--901},
  number = {6},
  month = {Sep},
  abstract = {The cortical motor system of primates is formed by a mosaic of anatomically
	and functionally distinct areas. These areas are not only involved
	in motor functions, but also play a role in functions formerly attributed
	to higher order associative cortical areas. In the present review,
	we discuss three types of higher functions carried out by the motor
	cortical areas: sensory-motor transformations, action understanding,
	and decision processing regarding action execution. We submit that
	generating internal representations of actions is central to cortical
	motor function. External contingencies and motivational factors determine
	then whether these action representations are transformed into actual
	actions.},
  file = {:/papers/Motor System/2001-Rizzolatti-MotorSystem.pdf:PDF},
  institution = {Istituto di Fisiologia Umana, Università di Parma, Via Volturno 39,
	I43100 Parma, Italy. fisioum@symbolic.parma.it},
  keywords = {Animals; Brain Mapping; Concept Formation, physiology; Decision Making,
	physiology; GABA Agonists, pharmacology; Hand Strength; Hand, physiology;
	Haplorhini, anatomy /&/ histology/physiology; Higher Nervous Activity,
	physiology; Humans; Imitative Behavior, physiology; Models, Neurological;
	Motor Activity, physiology; Motor Cortex, anatomy /&/ histology/physiology;
	Muscimol, pharmacology; Neural Pathways, physiology; Neurons, classification/physiology;
	Observation; Parietal Lobe, physiology; Pattern Recognition, Visual,
	physiology; Psychomotor Performance, drug effects/physiology; Sensation,
	physiology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {cheese63},
  pii = {S0896-6273(01)00423-8},
  pmid = {11580891},
  review = {- Divides motor cortex into an anterior "fronto-dependent" region
	and posterior "parieto-dependent" region.
	
	- Primary sensory cortex S1 is sandwiched between regions
	
	- Fronto-dependent regions don't connect to F1.
	
	- Parieto-dependent regions have some direct projections to spinal
	cord.
	
	- Parieto-dependent regions probably perform direct sensory-motor
	transformations},
  timestamp = {2011.07.14}
}

@ARTICLE{Rizzolatti1998,
  author = {G. Rizzolatti and G. Luppino and M. Matelli},
  title = {The organization of the cortical motor system: new concepts.},
  journal = {Electroencephalogr Clin Neurophysiol},
  year = {1998},
  volume = {106},
  pages = {283--296},
  number = {4},
  month = {Apr},
  abstract = {A series of recent anatomical and functional data has radically changed
	our view on the organization of the motor cortex in primates. In
	the present article we present this view and discuss its fundamental
	principles. The basic principles are the following: (a) the motor
	cortex, defined as the agranular frontal cortex, is formed by a mosaic
	of separate areas, each of which contains an independent body movement
	representation, (b) each motor area plays a specific role in motor
	control, based on the specificity of its cortical afferents and descending
	projections, (c) in analogy to the motor cortex, the posterior parietal
	cortex is formed by a multiplicity of areas, each of which is involved
	in the analysis of particular aspects of sensory information. There
	are no such things as multipurpose areas for space or body schema
	and (d) the parieto-frontal connections form a series of segregated
	anatomical circuits devoted to specific sensorimotor transformations.
	These circuits transform sensory information into action. They represent
	the basic functional units of the motor system. Although these conclusions
	mostly derive from monkey experiments, anatomical and brain-imaging
	evidence suggest that the organization of human motor cortex is based
	on the same principles. Possible homologies between the motor cortices
	of humans and non-human primates are discussed.},
  file = {:/papers/Motor System/1998-Rizzolatti-The organization of the cortical motor system.pdf:PDF},
  institution = {Istituto di Fisiologia Umana, Università di Parma, Italy. fisioum@symbolic.pr.it},
  keywords = {Animals; Humans; Motor Cortex, physiology; Neural Pathways, physiology;
	Primates, physiology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {cheese63},
  pii = {S0013469498000224},
  pmid = {9741757},
  timestamp = {2011.07.14}
}

@ARTICLE{Shadmehr2010,
  author = {Reza Shadmehr and Maurice A Smith and John W Krakauer},
  title = {Error correction, sensory prediction, and adaptation in motor control.},
  journal = {Annu Rev Neurosci},
  year = {2010},
  volume = {33},
  pages = {89--108},
  abstract = {Motor control is the study of how organisms make accurate goal-directed
	movements. Here we consider two problems that the motor system must
	solve in order to achieve such control. The first problem is that
	sensory feedback is noisy and delayed, which can make movements inaccurate
	and unstable. The second problem is that the relationship between
	a motor command and the movement it produces is variable, as the
	body and the environment can both change. A solution is to build
	adaptive internal models of the body and the world. The predictions
	of these internal models, called forward models because they transform
	motor commands into sensory consequences, can be used to both produce
	a lifetime of calibrated movements, and to improve the ability of
	the sensory system to estimate the state of the body and the world
	around it. Forward models are only useful if they produce unbiased
	predictions. Evidence shows that forward models remain calibrated
	through motor adaptation: learning driven by sensory prediction errors.},
  doi = {10.1146/annurev-neuro-060909-153135},
  file = {:/papers/Motor System/2010-Shadmehr-MotorControl.pdf:PDF},
  institution = {Department of Biomedical Engineering, Johns Hopkins School of Medicine,
	Baltimore, Maryland 21205, USA. shadmehr@jhu.edu},
  keywords = {Adaptation, Physiological, physiology; Animals; Feedback, Physiological,
	physiology; Humans; Movement, physiology; Predictive Value of Tests;
	Psychomotor Performance, physiology; Sensation, physiology; Sensory
	Receptor Cells, physiology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {cheese63},
  pmid = {20367317},
  review = {- Cerebellum can help deal with variablility in sensory state during
	motor actions
	
	- Implicates the cerebellum in generating a "forward model" of action
	state
	
	- A forward model is one that predicts the sensory consequences of
	a motor action
	
	- Theorizes that the cerebellum predicts the state of the the limb
	from the history of motor commands, complementing estimated state
	from sensory input
	
	- When taking a picture of a moving target, the background seems to
	go in the opposite direction. The reason it doesn't look like this
	to the brain is because the brain produces a prediction of what the
	shifted visual image should look like due to a saccade
	
	- There are two data streams: the observed sensory environment scene
	and the predicted sensory environment
	
	- When the prediction is viewed as the prior, and the sensory input
	as the evidence, the optimal weighted integration of the two can
	be accomplished using a Kalman filter. The Kalman filter minimizes
	the variance of the predicted sensory state
	
	- Kording and Wolpert (2004) perform experiments where the sensory
	input is probabalistic and the weighting of it is dependent on it's
	variance
	
	- More: "Bayesian integration also explains feedback responses to
	force perturbations (Kording et al. 2004), feedback responses to
	perturbations to the properties of the target (Izawa & Shadmehr 2008),
	and perceptual estimates of position and velocity in the presence
	of noise (Ernst & Banks 2002, Weiss et al. 2002, Stocker & Simoncelli
	2006, Sato et al. 2007)."
	
	- error feedback learning theory of the cerebellum (Kawato 1996)},
  timestamp = {2011.07.14},
  url = {http://dx.doi.org/10.1146/annurev-neuro-060909-153135}
}

@ARTICLE{Singer1999,
  author = {Wolf Singer},
  title = {Neuronal synchrony: a versatile code for the definition of relations?},
  journal = {Neuron},
  year = {1999},
  volume = {24},
  pages = {49--65, 111-25},
  number = {1},
  month = {Sep},
  file = {:/papers/Oscillations/1999-singer-oscillations.pdf:PDF},
  institution = {Max-Planck-Institute for Brain Research, Frankfurt, Federal Republic
	of Germany. singer@mpih-frankfurt.mpg.de},
  keywords = {Animals; Cerebral Cortex, physiology; Humans; Mental Processes, physiology;
	Neurons, physiology; Synaptic Transmission, physiology; Time Factors;
	Visual Perception, physiology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {cheese63},
  pii = {S0896-6273(00)80821-1},
  pmid = {10677026},
  review = {- Oscillatory firing of V1 neurons at gamma frequencies, range 30-50
	Hz (1 spike per 20 ms)
	
	- Synchronous firing at certain phase of oscillation
	
	- Talks about identifying a visual scene based on spatial cues or
	temporal cues. States that these cues are potentially in competition
	for defining a visual object.
	
	- Spatial configurations of elements appear grouped together if they
	appear within <10ms of eachother
	
	- Magnocellular pathway is very sensitive to temporal aspects of visual
	stimulus, lower spatial resolution
	
	- Parvocellular pathway has lower temporal resolution and high spatial
	resolution
	
	- Leonards and Singer 1998 show magnocellular pathway groups temporal
	cues, magno+parvo group non-temporal cues
	
	- They suggest spatial and temporal cues are processed in parallel
	and compete to group things together, the more salient grouping effect
	is used
	
	
	- Simulation papers on synchronization:
	
	Bauer and Pawelzik, 1993; Deppisch et al., 1993;
	
	Gerstner and van Hemmen, 1993;
	
	van Vreeswijk et al., 1994; 
	
	Hopfield and Hertz, 1995;
	
	Gerstner et al., 1996)},
  timestamp = {2011.07.19}
}

@BOOK{Strang2006,
  title = {Linear Algebra and it's Applications (4th Edition)},
  publisher = {Thomson Brooks/Cole},
  year = {2006},
  author = {Gilbert Strang},
  owner = {cheese63},
  timestamp = {2011.12.05}
}

@ARTICLE{WainwrightJordan2008,
  author = {Martin J. Wainwright and Michael L. Jordan},
  title = {Graphical Models, Exponential Families, and
	
	Variational Inference},
  journal = {Foundations and Trends in Machine Learning},
  year = {2008},
  volume = {Vol. 1, Nos. 1–2},
  pages = {1-305},
  abstract = {The formalism of probabilistic graphical models provides a unifying
	
	framework for capturing complex dependencies among random
	
	variables, and building large-scale multivariate statistical models.
	
	Graphical models have become a focus of research in many statistical,
	
	computational and mathematical fields, including bioinformatics,
	
	communication theory, statistical physics, combinatorial optimization,
	
	signal and image processing, information retrieval and statistical
	
	machine learning. Many problems that arise in specific instances —
	
	including the key problems of computing marginals and modes of
	
	probability distributions — are best studied in the general setting.
	
	Working with exponential family representations, and exploiting the
	
	conjugate duality between the cumulant function and the entropy
	
	for exponential families, we develop general variational representations
	
	of the problems of computing likelihoods, marginal probabilities
	
	and most probable configurations. We describe how a wide variety
	
	of algorithms — among them sum-product, cluster variational methods,
	
	expectation-propagation, mean field methods, max-product and
	
	linear programming relaxation, as well as conic programming relaxations
	
	— can all be understood in terms of exact or approximate forms
	
	of these variational representations. The variational approach provides
	
	a complementary alternative to Markov chain Monte Carlo as a general
	
	source of approximation methods for inference in large-scale statistical
	
	models.},
  doi = {10.1561/2200000001},
  file = {:/papers/Machine Learning/2008-WainrightJordan-Graphical.pdf:PDF},
  owner = {cheese63},
  timestamp = {2011.07.14}
}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:}

@comment{jabref-meta: groupsversion:3;}

@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:Animals\;2\;;
2 ExplicitGroup:Cat\;0\;;
2 ExplicitGroup:Fly\;0\;;
2 ExplicitGroup:Monkey\;0\;Gold2007\;Rizzolatti1998\;Rizzolatti2001\;;
2 ExplicitGroup:Human\;0\;Rizzolatti1998\;Rizzolatti2001\;;
2 ExplicitGroup:Rat\;2\;Ferezou2006\;Petersen2007a\;;
2 ExplicitGroup:Mouse\;2\;Petersen2007a\;;
1 ExplicitGroup:Neural Coding\;2\;;
2 ExplicitGroup:Adaptation\;0\;;
2 ExplicitGroup:Input-Output Function\;0\;;
1 ExplicitGroup:Information Theory\;2\;;
1 ExplicitGroup:Machine Learning\;2\;DumitruErhan2010\;Larouchelle2011
\;WainwrightJordan2008\;;
2 ExplicitGroup:Graphical Models\;0\;DumitruErhan2010\;Larouchelle2011
\;WainwrightJordan2008\;;
2 ExplicitGroup:Kalman Filter\;0\;Shadmehr2010\;;
2 ExplicitGroup:Deep Nets\;2\;DumitruErhan2010\;Larouchelle2011\;;
2 ExplicitGroup:Signal Detection Theory, Sequential Analysis\;0\;Gold2
007\;;
1 ExplicitGroup:Motor\;2\;Cisek2010\;Gold2007\;Rizzolatti1998\;Rizzola
tti2001\;Shadmehr2010\;;
2 ExplicitGroup:Saccades\;2\;Gold2007\;Shadmehr2010\;;
1 ExplicitGroup:Regions\;0\;;
2 ExplicitGroup:Cerebellum\;2\;Shadmehr2010\;;
2 ExplicitGroup:Thalamus\;2\;;
2 ExplicitGroup:Cortex\;2\;Gold2007\;Shadmehr2010\;;
3 ExplicitGroup:MT\;0\;Gold2007\;;
3 ExplicitGroup:PFC\;0\;Gold2007\;;
3 ExplicitGroup:S1\;0\;Gold2007\;Petersen2007a\;Rizzolatti2001\;;
3 ExplicitGroup:S2\;0\;Gold2007\;;
3 ExplicitGroup:Pre-motor\;0\;Gold2007\;;
3 ExplicitGroup:Motor\;0\;Gold2007\;;
3 ExplicitGroup:FEF\;0\;Gold2007\;;
3 ExplicitGroup:LIP\;0\;Fries2009a\;Gold2007\;;
3 ExplicitGroup:V1\;0\;Fries2009a\;Singer1999\;;
1 ExplicitGroup:Sensorimotor\;2\;Gold2007\;Rizzolatti1998\;Shadmehr201
0\;;
1 ExplicitGroup:Sensory\;2\;;
2 ExplicitGroup:Auditory\;2\;;
2 ExplicitGroup:Vision\;2\;Shadmehr2010\;;
2 ExplicitGroup:Somatosensory\;2\;Petersen2007a\;;
3 ExplicitGroup:Whisker\;0\;Ferezou2006\;Petersen2007a\;;
1 ExplicitGroup:Sychronicity/Oscillations\;0\;Fries2009a\;Singer1999\;
;
1 ExplicitGroup:Networks\;2\;Fries2009a\;;
2 ExplicitGroup:Winner-take-all\;0\;Fries2009a\;;
2 ExplicitGroup:Reservoir\;0\;Jaeger2001\;Legenstein2007\;Maass2002\;;
1 ExplicitGroup:Techniques\;0\;;
2 ExplicitGroup:Voltage-Sensitive Dye\;0\;Ferezou2006\;;
2 ExplicitGroup:Multi-electrode\;0\;Csicsvari2003\;;
2 ExplicitGroup:Silicon Depth\;0\;Csicsvari2003\;;
}

